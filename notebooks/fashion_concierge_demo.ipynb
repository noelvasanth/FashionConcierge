{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66c6121",
   "metadata": {},
   "source": [
    "# Fashion Concierge – Interactive Demo Notebook\n",
    "\n",
    "This notebook is an **interactive front end** for the Fashion Concierge project built with the\n",
    "**Google Agent Development Kit (ADK)** and **Gemini**.\n",
    "\n",
    "It is designed to work for **any user** who has access to the repository, whether they run it:\n",
    "\n",
    "- in **GitHub Codespaces**, or  \n",
    "- in a local Python environment (VS Code, Jupyter Lab, etc.).\n",
    "\n",
    "The notebook demonstrates three core capabilities:\n",
    "\n",
    "1. Wiring the notebook to the **Fashion Concierge backend** (the `FashionConciergeApp` class in `adk_app/app.py`).  \n",
    "2. Running **one end-to-end outfit suggestion** through the agent pipeline.  \n",
    "3. Showing a **simple session and memory example** where the agent remembers user preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30c46d",
   "metadata": {},
   "source": [
    "## 0. How to use this notebook\n",
    "\n",
    "### 0.1 Open the notebook in GitHub Codespaces\n",
    "\n",
    "1. Navigate to the Fashion Concierge repository on GitHub.  \n",
    "2. Click **Code → Open with Codespaces → New codespace**.  \n",
    "3. When the Codespace finishes starting, open this notebook file (for example `notebooks/fashion_concierge_demo.ipynb`) in the editor.  \n",
    "4. Select the default Python kernel for the Codespace.\n",
    "\n",
    "> You can also run this notebook locally if you prefer. The steps are the same after cloning the repo.\n",
    "\n",
    "### 0.2 Install dependencies\n",
    "\n",
    "Inside the Codespace (or your local terminal), run once:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "# or, if the project is packaged\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "### 0.3 Configure credentials\n",
    "\n",
    "Make sure the environment has credentials for:\n",
    "\n",
    "- Google Gemini / Vertex AI (for the LLM calls).  \n",
    "- Any external tools you actually use (calendar, weather, etc.), if those are enabled.\n",
    "\n",
    "In many setups this is handled via environment variables (`GOOGLE_API_KEY`, `GOOGLE_CLOUD_PROJECT`, etc.).\n",
    "The next section will show where these are read.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1addc8fc",
   "metadata": {},
   "source": [
    "## 1. Environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment and path setup.\n",
    "\n",
    "This cell:\n",
    "\n",
    "1. Locates the repository root (so imports work whether the notebook lives in\n",
    "   the root or in a subfolder like `notebooks/`).\n",
    "2. Adds the repo root to `sys.path`.\n",
    "3. Sets **placeholder** environment variables for Google Cloud / Gemini so that\n",
    "   the rest of the code can read them. In Codespaces or local dev you should\n",
    "   either:\n",
    "   - export real values before starting Jupyter, or\n",
    "   - edit the placeholders below.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Locate the project root --------------------------------------------------\n",
    "# We look upwards from the notebook directory until we find the marker folder\n",
    "# `adk_app` (which exists in this repo) or a `.git` directory.\n",
    "current = Path().resolve()\n",
    "project_root = None\n",
    "\n",
    "for parent in [current] + list(current.parents):\n",
    "    if (parent / \"adk_app\").exists() or (parent / \".git\").exists():\n",
    "        project_root = parent\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not locate the project root. Make sure you are running this \"\n",
    "        \"notebook inside the Fashion Concierge repository.\"\n",
    "    )\n",
    "\n",
    "print(\"Detected project root:\", project_root)\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Sanity check\n",
    "if not (project_root / \"adk_app\").exists():\n",
    "    raise RuntimeError(\n",
    "        \"The 'adk_app' package was not found at the detected project root. \"\n",
    "        \"Please confirm the repo layout.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Found 'adk_app' package. Imports should work.\")\n",
    "\n",
    "# --- Environment variables for Google / tools ---------------------------------\n",
    "# These are **placeholders**. Replace with real values or rely on values\n",
    "# already exported in the environment. Using `setdefault` means they will\n",
    "# not override anything you configured outside the notebook.\n",
    "os.environ.setdefault(\"GOOGLE_CLOUD_PROJECT\", \"YOUR_GCP_PROJECT_ID_HERE\")\n",
    "os.environ.setdefault(\"GOOGLE_CLOUD_LOCATION\", \"YOUR_GCP_REGION_HERE\")  # e.g. \"europe-west4\"\n",
    "os.environ.setdefault(\"GOOGLE_API_KEY\", \"YOUR_GEMINI_API_KEY_HERE\")\n",
    "\n",
    "print(\"GOOGLE_CLOUD_PROJECT:\", os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "print(\"GOOGLE_CLOUD_LOCATION:\", os.environ.get(\"GOOGLE_CLOUD_LOCATION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1aecc3",
   "metadata": {},
   "source": [
    "## 2. Load the Fashion Concierge backend\n",
    "\n",
    "The Fashion Concierge backend is wrapped in a convenience class `FashionConciergeApp`\n",
    "defined in `adk_app/app.py`.\n",
    "\n",
    "This class is responsible for:\n",
    "\n",
    "- Constructing the ADK `App` object.  \n",
    "- Registering all agents (calendar, weather, wardrobe, stylist, critic, etc.).  \n",
    "- Exposing high-level methods for:\n",
    "  - creating sessions  \n",
    "  - orchestrating outfit planning  \n",
    "  - running conversations\n",
    "\n",
    "We import and instantiate it here.\n",
    "\n",
    "> If your repository uses a different entry point (for example a `create_app()`\n",
    "> function), you only need to adapt the import below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adk_app.app import FashionConciergeApp  # adapt if your module name differs\n",
    "\n",
    "fashion_app = FashionConciergeApp()\n",
    "\n",
    "print(\"FashionConciergeApp instance:\", fashion_app)\n",
    "print(\"Public attributes:\", [a for a in dir(fashion_app) if not a.startswith(\"_\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc7368",
   "metadata": {},
   "source": [
    "### 2.1 Helper functions for sessions and outfit orchestration\n",
    "\n",
    "The HTTP API layer (in `server/api.py`) usually calls methods on `FashionConciergeApp`\n",
    "to:\n",
    "\n",
    "- create a new session, and  \n",
    "- orchestrate an outfit recommendation.\n",
    "\n",
    "To make the notebook easier to read, we mirror that behaviour with two helper\n",
    "functions:\n",
    "\n",
    "- `create_demo_session(...)`  \n",
    "- `orchestrate_outfit(...)`  \n",
    "\n",
    "If the method names in your implementation differ, you can adjust **only this\n",
    "section** and the rest of the notebook will still work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any, Any\n",
    "\n",
    "def create_demo_session(metadata: Optional[Dict[str, Any]] = None):\n",
    "    \"\"\"Create a new session through `FashionConciergeApp`.\n",
    "\n",
    "    Expected backend method:\n",
    "        fashion_app.create_session(metadata: dict | None) -> Session\n",
    "\n",
    "    If your app exposes a different method name, update this function.\n",
    "    \"\"\"\n",
    "    if not hasattr(fashion_app, \"create_session\"):\n",
    "        raise AttributeError(\n",
    "            \"FashionConciergeApp has no 'create_session' method. \"\n",
    "            \"Open adk_app/app.py and either expose one or adapt this helper.\"\n",
    "        )\n",
    "\n",
    "    session = fashion_app.create_session(metadata=metadata or {\"source\": \"notebook-demo\"})\n",
    "    session_id = getattr(session, \"session_id\", None) or getattr(session, \"id\", None)\n",
    "\n",
    "    print(\"Created session object:\", session)\n",
    "    print(\"Session id:\", session_id)\n",
    "    return session, session_id\n",
    "\n",
    "\n",
    "def orchestrate_outfit(\n",
    "    session_id: str,\n",
    "    user_query: str,\n",
    "    location: str = \"Amsterdam, NL\",\n",
    "    date_iso: Optional[str] = None,\n",
    "    mood: Optional[str] = None,\n",
    ") -> Any:\n",
    "    \"\"\"Call the high-level outfit orchestration method.\n",
    "\n",
    "    The exact method name may differ slightly between versions of the repo.\n",
    "    Common options are:\n",
    "\n",
    "    - `orchestrate_outfit`\n",
    "    - `plan_outfit`\n",
    "    - `run_outfit_orchestration`\n",
    "\n",
    "    This helper tries those in order. If none exist, update this function to\n",
    "    call the appropriate method on `fashion_app`.\n",
    "    \"\"\"\n",
    "    candidate_method_names = [\"orchestrate_outfit\", \"plan_outfit\", \"run_outfit_orchestration\"]\n",
    "\n",
    "    method = None\n",
    "    for name in candidate_method_names:\n",
    "        if hasattr(fashion_app, name):\n",
    "            method = getattr(fashion_app, name)\n",
    "            break\n",
    "\n",
    "    if method is None:\n",
    "        raise AttributeError(\n",
    "            \"Could not find any of the expected outfit orchestration methods on \"\n",
    "            \"FashionConciergeApp. Please open adk_app/app.py and update the \"\n",
    "            \"helper `orchestrate_outfit` accordingly.\"\n",
    "        )\n",
    "\n",
    "    response = method(\n",
    "        session_id=session_id,\n",
    "        user_query=user_query,\n",
    "        location=location,\n",
    "        date=date_iso,\n",
    "        mood=mood,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bb487",
   "metadata": {},
   "source": [
    "## 3. End-to-end outfit suggestion demo\n",
    "\n",
    "This section runs a **single full interaction**:\n",
    "\n",
    "1. Create a fresh session.  \n",
    "2. Ask the agent to plan outfits for a given day, location and mood.  \n",
    "3. Inspect the structured result and any natural language rationale.\n",
    "\n",
    "If your backend is wired as intended, this will exercise:\n",
    "\n",
    "- the **calendar agent** (to infer formality and schedule),  \n",
    "- the **weather agent** (to choose layers and fabrics), and  \n",
    "- the **wardrobe / stylist agents** (to assemble and score outfit combinations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a new session for this demo\n",
    "session, session_id = create_demo_session(metadata={\"demo\": \"single-day-outfit\"})\n",
    "\n",
    "# 2. Define the high-level request for the orchestrator\n",
    "user_query = (\n",
    "    \"I am in Amsterdam this Friday with a full workday and casual drinks after. \"\n",
    "    \"Suggest one daytime outfit and one outfit that can transition into the evening. \"\n",
    "    \"Keep the mood 'trendy' but practical for commuting by bike.\"\n",
    ")\n",
    "\n",
    "# Optional: you can specify a particular date if your backend expects it, e.g. \"2025-11-28\"\n",
    "demo_date = None  # or \"2025-11-28\"\n",
    "\n",
    "# 3. Call the orchestrator\n",
    "outfit_response = orchestrate_outfit(\n",
    "    session_id=session_id,\n",
    "    user_query=user_query,\n",
    "    location=\"Amsterdam, NL\",\n",
    "    date_iso=demo_date,\n",
    "    mood=\"trendy\",\n",
    ")\n",
    "\n",
    "outfit_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c1598",
   "metadata": {},
   "source": [
    "### 3.1 Interpreting the result\n",
    "\n",
    "The variable `outfit_response` may be:\n",
    "\n",
    "- a plain string (just text),  \n",
    "- a Pydantic model / dataclass, or  \n",
    "- a nested dictionary with keys like `outfits`, `candidates`, `context`, etc.\n",
    "\n",
    "For inspection and debugging it helps to **look at the raw object** and then\n",
    "pull out key parts (for example, outfit items and their scores). The helper\n",
    "below tries to do this in a best-effort way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f56962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def pretty_print_outfits(resp):\n",
    "    \"\"\"Best-effort pretty printer for common response shapes.\"\"\"\n",
    "    if resp is None:\n",
    "        print(\"No response returned.\")\n",
    "        return\n",
    "\n",
    "    obj = resp\n",
    "    if hasattr(resp, \"model_dump\"):\n",
    "        obj = resp.model_dump()\n",
    "    elif hasattr(resp, \"dict\"):\n",
    "        obj = resp.dict()\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        print(\"Top-level keys:\", list(obj.keys()))\n",
    "        for key in (\"outfits\", \"candidates\", \"suggestions\"):\n",
    "            if key in obj:\n",
    "                print(\"\\n===\", key, \"===\")\n",
    "                pprint(obj[key], depth=3)\n",
    "                break\n",
    "        else:\n",
    "            pprint(obj, depth=3)\n",
    "    else:\n",
    "        print(obj)\n",
    "\n",
    "\n",
    "pretty_print_outfits(outfit_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67185fa",
   "metadata": {},
   "source": [
    "## 4. Session and memory demo\n",
    "\n",
    "Now we demonstrate how sessions and memory work together.\n",
    "\n",
    "1. Start a **new session**.  \n",
    "2. First turn: the user describes a long-term style preference.  \n",
    "3. Second turn: the user asks for an outfit; the agent should incorporate that preference.\n",
    "\n",
    "This relies on your backend wiring a conversational entry point that:\n",
    "\n",
    "- keeps **short-term state** in the ADK session, and  \n",
    "- optionally writes **long-term preferences** into a memory store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dedicated session for the memory demo\n",
    "memory_session, memory_session_id = create_demo_session(metadata={\"demo\": \"memory\"})\n",
    "\n",
    "# Turn 1 – the user states a preference\n",
    "pref_query = \"Remember that I prefer monochrome outfits with chunky sneakers and no logos.\"\n",
    "\n",
    "# Many backends expose a generic conversation method, for example `run_conversation`.\n",
    "# If your `FashionConciergeApp` uses a different name (e.g. `chat` or `orchestrate_chat`),\n",
    "# adjust the call below.\n",
    "if hasattr(fashion_app, \"run_conversation\"):\n",
    "    first_turn = fashion_app.run_conversation(\n",
    "        session_id=memory_session_id,\n",
    "        user_query=pref_query,\n",
    "    )\n",
    "else:\n",
    "    raise AttributeError(\n",
    "        \"This notebook expects a high-level conversation method named \"\n",
    "        \"'run_conversation' on FashionConciergeApp. \"\n",
    "        \"Update this cell to call whichever method your app uses.\"\n",
    "    )\n",
    "\n",
    "print(\"First turn response:\\n\", first_turn, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57509c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 2 – ask for a casual outfit; the agent should remember the preference.\n",
    "\n",
    "followup_query = \"Now suggest an outfit for a relaxed Sunday brunch in Amsterdam.\"\n",
    "\n",
    "second_turn = fashion_app.run_conversation(\n",
    "    session_id=memory_session_id,\n",
    "    user_query=followup_query,\n",
    ")\n",
    "\n",
    "print(\"Second turn response:\\n\", second_turn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97aab35",
   "metadata": {},
   "source": [
    "## 5. Where to go next\n",
    "\n",
    "Once the basic flows above are working, you can extend this notebook to:\n",
    "\n",
    "- Visualise **agent traces** (tool calls, reasoning steps) for a given session.  \n",
    "- Call your **evaluation harness** to run predefined scenarios and compute scores.  \n",
    "- Show how this notebook maps to the **HTTP API** in `server/api.py`, and how the same\n",
    "  patterns apply when deploying to **Vertex AI Agent Engine** or **Cloud Run**.\n",
    "\n",
    "Because this notebook is designed to run from inside the repository (including\n",
    "GitHub Codespaces), you can commit it to version control and treat it as both:\n",
    "\n",
    "- a **developer tool** for experimenting with the agent, and  \n",
    "- a **readable artifact** for your capstone submission.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}